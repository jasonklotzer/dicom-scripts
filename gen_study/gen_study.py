# -*- coding: utf-8 -*-
import pydicom
from pydicom.dataset import Dataset, FileMetaDataset
from pydicom.sequence import Sequence
from pydicom.uid import generate_uid, ExplicitVRLittleEndian
from pydicom.uid import UID
from pydicom.datadict import keyword_dict, tag_for_keyword, dictionary_VR

import random
import datetime
import string
import os
from pathlib import Path
from faker import Faker
import argparse
import numpy as np
try:
    from scipy.ndimage import gaussian_filter
    HAS_SCIPY = True
except ImportError:
    HAS_SCIPY = False
import sys # Import sys to check Python version for encoding and for stderr

# --- Configuration ---
NUM_IMAGES = 19
BASE_OUTPUT_DIR = "dicom_studies_output" # Changed name to reflect it's the base
PATIENT_ID_LENGTH = 10
ACCESSION_NUMBER_LENGTH = 12
IMAGING_MODALITIES = ["CT", "MR", "XA", "CR", "US"]
SOP_CLASS_UIDS = {
    "CT": "1.2.840.10008.5.1.4.1.1.2",
    "MR": "1.2.840.10008.5.1.4.1.1.4",
    "XA": "1.2.840.10008.5.1.4.1.1.12.1",
    "CR": "1.2.840.10008.5.1.4.1.1.1",
    "US": "1.2.840.10008.5.1.4.1.1.6.1",
    "SR": "1.2.840.10008.5.1.4.1.1.88.11"
}
# Default character set, ensure it handles names generated by Faker
DEFAULT_CHARACTER_SET = "ISO_IR 192" # UTF-8

# --- New Configuration: Modality-based Study Descriptions ---
MODALITY_DESCRIPTIONS = {
    "CT": [
        "CT Abdomen and Pelvis w/ Contrast", "CT Chest w/o Contrast", "CT Head/Brain w/o Contrast",
        "CT Neck Soft Tissue w/ Contrast", "CT Angiography Chest", "Low-Dose CT Lung Screening",
        "CT Spine Cervical Spine w/o Contrast", "CT Enterography"
    ],
    "MR": [
        "MRI Brain w/ + w/o Contrast", "MRI Lumbar Spine w/o Contrast", "MRI Knee Right w/o Contrast",
        "MRI Abdomen w/ + w/o Contrast", "MRCP", "MRI Shoulder Left w/ + w/o Contrast",
        "MRI Pelvis w/o Contrast for Fistula", "MRA Brain Circle of Willis"
    ],
    "XA": [
        "Coronary Angiography", "Cerebral Angiography", "Peripheral Angiography Lower Extremity",
        "Angioplasty and Stent Placement", "Embolization Procedure", "Diagnostic Aortogram"
    ],
    "CR": [
        "Chest X-Ray PA and Lateral", "Abdomen KUB Supine", "Hand X-Ray 3 Views Left",
        "Portable Chest X-Ray AP", "Foot X-Ray Right", "Cervical Spine 3 Views",
        "Skull X-Ray Series"
    ],
    "US": [
        "Ultrasound Abdomen Complete", "Ultrasound Pelvis Transabdominal", "Ultrasound Thyroid",
        "Ultrasound Renal Complete", "Doppler Carotid Arteries", "Ultrasound Venous Doppler Lower Extremity Right",
        "Ultrasound Obstetric First Trimester", "Ultrasound Scrotum"
    ],
    "DEFAULT": [ # Fallback for other modalities or if chosen_modality is not in dict
        "Diagnostic Imaging Study", "Radiology Procedure", "Follow-up Examination"
    ]
}

# --- NEW Configuration: BodyPartExamined Mappings ---
# Maps StudyDescription (or modality as fallback key) to a list of BodyPartExamined values.
# The first value is considered primary/default for non-jumbled mode.
# Values should be uppercase as per DICOM standard practice for CS VR.
STUDY_DESCRIPTION_TO_BODY_PARTS = {
    # CT Studies
    "CT Abdomen and Pelvis w/ Contrast": ["ABDOMENPELVIS", "ABDOMEN", "PELVIS", "ABDPEL"],
    "CT Chest w/o Contrast": ["CHEST", "THORAX", "LUNG", "MEDIASTINUM"],
    "CT Head/Brain w/o Contrast": ["HEAD", "BRAIN", "SKULL", "CRANIUM"],
    "CT Neck Soft Tissue w/ Contrast": ["NECK", "SOFT TISSUE NECK", "CERVICAL REGION"],
    "CT Angiography Chest": ["CHEST", "THORAX", "AORTA", "PULMONARY ARTERIES"],
    "Low-Dose CT Lung Screening": ["LUNG", "CHEST", "THORAX"],
    "CT Spine Cervical Spine w/o Contrast": ["CSPINE", "SPINE", "CERVICAL", "VERTEBRAE C-SPINE"],
    "CT Enterography": ["ABDOMEN", "SMALL BOWEL", "ENTERIC REGION", "JEJUNUM ILEUM"],
    # MR Studies
    "MRI Brain w/ + w/o Contrast": ["BRAIN", "HEAD", "CRANIUM", "CEREBRUM"],
    "MRI Lumbar Spine w/o Contrast": ["LSPINE", "SPINE", "LUMBAR", "VERTEBRAE L-SPINE"],
    "MRI Knee Right w/o Contrast": ["KNEE", "KNEE_RT", "RIGHT KNEE", "FEMUR TIBIA PATELLA"],
    "MRI Knee Left w/o Contrast": ["KNEE", "KNEE_LT", "LEFT KNEE", "FEMUR TIBIA PATELLA"], # Added for completeness
    "MRI Abdomen w/ + w/o Contrast": ["ABDOMEN", "LIVER", "PANCREAS", "ABDOMINAL VISCERA"],
    "MRCP": ["ABDOMEN", "BILIARY", "GALLBLADDER", "HEPATOBILIARY"],
    "MRI Shoulder Left w/ + w/o Contrast": ["SHOULDER", "SHOULDER_LT", "LEFT SHOULDER", "GLENOHUMERAL JOINT"],
    "MRI Shoulder Right w/ + w/o Contrast": ["SHOULDER", "SHOULDER_RT", "RIGHT SHOULDER", "GLENOHUMERAL JOINT"], # Added for completeness
    "MRI Pelvis w/o Contrast for Fistula": ["PELVIS", "PERINEUM", "ANAL CANAL", "RECTUM"],
    "MRA Brain Circle of Willis": ["HEAD", "BRAIN", "CIRCLE OF WILLIS", "CEREBRAL ARTERIES"],
    # XA Studies
    "Coronary Angiography": ["HEART", "CORONARY ARTERIES", "CHEST", "CARDIAC"],
    "Cerebral Angiography": ["HEAD", "BRAIN", "CEREBRAL VESSELS", "CAROTID"],
    "Peripheral Angiography Lower Extremity": ["EXTREMITY", "LOWER LIMB", "LEG", "FEMORAL ARTERY", "TIBIAL ARTERY"],
    "Angioplasty and Stent Placement": ["VESSEL", "ARTERY", "VASCULAR", "TARGET VESSEL"], # Generic for XA intervention
    "Embolization Procedure": ["TARGET ORGAN", "VASCULAR TERRITORY", "SUPPLYING ARTERY"], # Generic for XA intervention
    "Diagnostic Aortogram": ["AORTA", "CHEST", "ABDOMEN", "THORACIC AORTA", "ABDOMINAL AORTA"],
    # CR Studies
    "Chest X-Ray PA and Lateral": ["CHEST", "LUNG", "THORAX", "RIBCAGE"],
    "Abdomen KUB Supine": ["ABDOMEN", "KUB", "ABDOMINAL REGION"],
    "Hand X-Ray 3 Views Left": ["HAND", "HAND_LT", "LEFT HAND", "WRIST"],
    "Hand X-Ray 3 Views Right": ["HAND", "HAND_RT", "RIGHT HAND", "WRIST"], # Added
    "Portable Chest X-Ray AP": ["CHEST", "LUNG", "PORTABLE CHEST"],
    "Foot X-Ray Right": ["FOOT", "FOOT_RT", "RIGHT FOOT", "ANKLE"],
    "Foot X-Ray Left": ["FOOT", "FOOT_LT", "LEFT FOOT", "ANKLE"], # Added
    "Cervical Spine 3 Views": ["CSPINE", "CERVICAL", "NECK", "SPINE"],
    "Skull X-Ray Series": ["SKULL", "HEAD", "CRANIUM", "FACIAL BONES"],
    # US Studies
    "Ultrasound Abdomen Complete": ["ABDOMEN", "LIVER", "SPLEEN", "KIDNEYS", "UPPER ABDOMEN"],
    "Ultrasound Pelvis Transabdominal": ["PELVIS", "UTERUS", "OVARIES", "BLADDER"],
    "Ultrasound Thyroid": ["THYROID", "NECK", "PARATHYROID"],
    "Ultrasound Renal Complete": ["KIDNEY", "RENAL", "RETROPERITONEUM", "ABDOMEN"],
    "Doppler Carotid Arteries": ["NECK", "CAROTID", "CAROTID ARTERY", "VERTEBRAL ARTERY"],
    "Ultrasound Venous Doppler Lower Extremity Right": ["EXTREMITY", "LEG_RT", "LOWER LIMB RT", "VEINS RT LEG"],
    "Ultrasound Venous Doppler Lower Extremity Left": ["EXTREMITY", "LEG_LT", "LOWER LIMB LT", "VEINS LT LEG"], # Added
    "Ultrasound Obstetric First Trimester": ["PELVIS", "UTERUS", "FETUS", "OBSTETRIC"],
    "Ultrasound Scrotum": ["SCROTUM", "TESTES", "EPIDIDYMIS", "TESTICLE"],
    # Modality-level fallbacks (if StudyDescription doesn't match)
    "DEFAULT_CT": ["CT_BODYPART", "REGION_OF_INTEREST_CT", "UNKNOWN"],
    "DEFAULT_MR": ["MR_BODYPART", "REGION_OF_INTEREST_MR", "UNKNOWN"],
    "DEFAULT_XA": ["VASCULAR_REGION", "ANGIO_SITE", "UNKNOWN"],
    "DEFAULT_CR": ["XRAY_BODYPART", "GENERAL_RADIOGRAPHY", "UNKNOWN"],
    "DEFAULT_US": ["ULTRASOUND_REGION", "AREA_OF_INTEREST_US", "UNKNOWN"],
    # Absolute fallback
    "DEFAULT_OVERALL": ["UNKNOWN", "NOT SPECIFIED", "BODY PART"]
}

# --- Helper Functions ---

def generate_random_string(length, chars=string.ascii_uppercase + string.digits):
    """Generates a random string of specified length."""
    return ''.join(random.choice(chars) for _ in range(length))

def generate_fake_report_text(fake, modality, study_description):
    """Generates plausible fake report text, incorporating study description."""
    # (Function remains unchanged)
    findings = [
        f"Evaluation of the {modality} images was performed.",
        "No acute abnormalities identified.",
        "Clinical correlation is recommended.",
        "Comparison is made to prior study dated YYYY-MM-DD.",
        "Findings are unremarkable.",
        f"The {modality} scan reveals findings consistent with [Pathology].",
        "Impression: Normal study.",
        "Further evaluation with [Follow-up Modality] may be warranted if clinically indicated.",
        "Measurements are within normal limits.",
        "Technique: Standard imaging protocols were utilized."
    ]
    report = f"STUDY: {study_description}\n\n" # Use the generated study description
    report += f"MODALITY: {modality}\n\n"
    report += f"INDICATION: {fake.sentence(nb_words=random.randint(4, 8))}\n\n"
    report += "FINDINGS:\n"
    num_findings = random.randint(2, 4)
    report += "\n".join(random.sample(findings, num_findings)) + "\n\n"
    report += f"IMPRESSION:\n{random.choice(findings)}"

    # Replace placeholders
    report = report.replace("[Pathology]", fake.bs().title())
    report = report.replace("[Follow-up Modality]", random.choice(IMAGING_MODALITIES))
    report = report.replace("YYYY-MM-DD", fake.past_date(start_date="-2y").strftime("%Y-%m-%d"))
    return report

def generate_patient_name_pn(fake: Faker) -> str:
    """Generate a DICOM PN (Person Name) in the form LAST^FIRST.

    Only two components are used as requested. Any caret characters from Faker are sanitized.
    """
    last = fake.last_name().strip().replace('^', ' ')
    first = fake.first_name().strip().replace('^', ' ')
    # Keep natural casing; DICOM PN doesn't require uppercase. Example shows LAST^FIRST.
    return f"{last}^{first}"

def random_dicom_date_within_last_100_years():
    """Return a random DICOM DA (YYYYMMDD) within the last 100 years up to today."""
    today = datetime.date.today()
    start = today - datetime.timedelta(days=36525)  # ~100 years accounting for leap years
    delta_days = (today - start).days
    rand_days = random.randint(0, delta_days)
    d = start + datetime.timedelta(days=rand_days)
    return d.strftime("%Y%m%d")

def random_dicom_birthdate_before(study_date_str):
    """Return a random DICOM DA (YYYYMMDD) for PatientBirthDate not after the given StudyDate and within the prior 100 years.

    If parsing fails, falls back to random_dicom_date_within_last_100_years().
    """
    try:
        study_date = datetime.datetime.strptime(study_date_str, "%Y%m%d").date()
    except Exception:
        return random_dicom_date_within_last_100_years()

    today = datetime.date.today()
    end = min(study_date, today)
    start = end - datetime.timedelta(days=36525)
    if start < datetime.date(1900, 1, 1):
        start = datetime.date(1900, 1, 1)
    delta_days = (end - start).days
    if delta_days <= 0:
        return end.strftime("%Y%m%d")
    rand_days = random.randint(0, delta_days)
    d = start + datetime.timedelta(days=rand_days)
    return d.strftime("%Y%m%d")

def generate_plausible_pixel_data(ds, instance_num, quiet=False): # Added quiet flag
    """Generates plausible, modality-specific fake pixel data using NumPy."""
    # (Function remains unchanged internally, except for the print statement)
    rows = ds.Rows
    cols = ds.Columns
    modality = ds.Modality
    bits_allocated = ds.BitsAllocated
    bits_stored = ds.BitsStored
    pixel_representation = ds.PixelRepresentation
    max_val = (1 << bits_stored) -1
    min_val = 0
    dtype = np.uint16
    if bits_allocated == 8:
        dtype = np.uint8 if pixel_representation == 0 else np.int8
        max_val = 255 if pixel_representation == 0 else 127
        min_val = 0 if pixel_representation == 0 else -128
    elif bits_allocated == 16:
        dtype = np.uint16 if pixel_representation == 0 else np.int16
        min_val = 0 if pixel_representation == 0 else -(1 << (bits_stored -1))
    else:
         dtype = np.uint16 # Default fallback

    if not quiet: # Check quiet flag before printing
        print(f"    Generating plausible pixel data for {modality} ({rows}x{cols}), Instance {instance_num}, dtype {dtype}, range [{min_val}, {max_val}]")
    pixels = np.zeros((rows, cols), dtype=np.float64)

    # --- Modality Specific Generation ---
    # (CT/MR, XA/CR, US logic remains unchanged)
    if modality in ["CT", "MR"]:
        center_x, center_y = cols // 2, rows // 2
        radius_x, radius_y = cols // random.uniform(2.5, 4), rows // random.uniform(2.5, 4)
        center_x += random.randint(-5, 5) * (instance_num % 5)
        radius_y -= random.randint(-3, 3) * (instance_num % 6)
        radius_x = max(10, radius_x); radius_y = max(10, radius_y)
        y, x = np.ogrid[:rows, :cols]
        mask = ((x - center_x)**2 / radius_x**2 + (y - center_y)**2 / radius_y**2 <= 1)
        structure_base = max_val * random.uniform(0.3, 0.6)
        pixels[mask] = structure_base
        noise_level = max_val * random.uniform(0.05, 0.15)
        pixels += np.random.normal(loc=0, scale=noise_level, size=(rows, cols))
        if modality == "MR":
            for _ in range(random.randint(2, 5)):
                blob_center_x = center_x + random.randint(-int(radius_x*0.6), int(radius_x*0.6))
                blob_center_y = center_y + random.randint(-int(radius_y*0.6), int(radius_y*0.6))
                blob_rad = min(radius_x, radius_y) * random.uniform(0.1, 0.3)
                blob_mask = ((x - blob_center_x)**2 + (y - blob_center_y)**2 <= blob_rad**2)
                pixels[blob_mask & mask] += max_val * random.uniform(-0.2, 0.2)
        if HAS_SCIPY: pixels = gaussian_filter(pixels, sigma=random.uniform(0.8, 1.5))
    elif modality in ["XA", "CR"]:
        pixels = np.random.uniform(min_val, max_val * 0.2, size=(rows, cols))
        num_lines = random.randint(3, 8)
        for _ in range(num_lines):
            x1, y1 = random.randint(0, cols-1), random.randint(0, rows-1)
            x2, y2 = random.randint(0, cols-1), random.randint(0, rows-1)
            intensity = max_val * random.uniform(0.7, 1.0)
            line_width = random.randint(2, 6)
            length = int(np.hypot(x2-x1, y2-y1));
            if length == 0: continue
            x_coords = np.linspace(x1, x2, length); y_coords = np.linspace(y1, y2, length)
            for i in range(1, line_width + 1):
                 coords = np.stack([np.clip(y_coords+(i-line_width//2), 0, rows-1),
                                    np.clip(x_coords, 0, cols-1)], axis=1).astype(int)
                 pixels[coords[:, 0], coords[:, 1]] = intensity
        if modality == "CR" and random.random() < 0.5:
            center_x, center_y = cols // 2 + random.randint(-cols//4, cols//4), rows // 2 + random.randint(-rows//4, rows//4)
            rad_x, rad_y = cols // random.randint(4, 6), rows // random.randint(4, 6)
            y, x = np.ogrid[:rows, :cols]; mask = ((x - center_x)**2 / rad_x**2 + (y - center_y)**2 / rad_y**2 <= 1)
            pixels[mask] = np.maximum(pixels[mask], max_val * random.uniform(0.3, 0.5))
        if HAS_SCIPY: pixels = gaussian_filter(pixels, sigma=random.uniform(0.5, 1.0))
    elif modality == "US":
        pixels = np.random.uniform(min_val, max_val * 0.05, size=(rows, cols))
        if random.random() < 0.6: # Sector
            center_x, center_y = cols // 2 + random.randint(-cols//10, cols//10) , rows -1
            max_radius = rows * random.uniform(0.8, 1.0); angle_start = np.radians(random.uniform(-60, -30)); angle_end = np.radians(random.uniform(30, 60))
            y, x = np.ogrid[:rows, :cols]; dist_sq = (x - center_x)**2 + (y - center_y)**2; angle = np.arctan2(x - center_x, -(y - center_y))
            mask = (dist_sq <= max_radius**2) & (angle >= angle_start) & (angle <= angle_end)
        else: # Rectangle
            start_x = random.randint(0, cols//4); end_x = random.randint(cols*3//4, cols-1); start_y = 0; end_y = random.randint(rows*3//4, rows-1)
            mask = np.zeros_like(pixels, dtype=bool); mask[start_y:end_y, start_x:end_x] = True
        speckle_base = max_val * random.uniform(0.2, 0.5)
        speckle_noise = np.random.uniform(0.5, 1.5, size=(rows, cols))
        pixels[mask] = speckle_base * speckle_noise[mask]
        num_blobs = random.randint(1, 4)
        for _ in range(num_blobs):
            valid_coords = np.argwhere(mask)
            if len(valid_coords) > 0:
                cy, cx = random.choice(valid_coords); blob_rad = random.uniform(rows*0.02, rows*0.08); blob_intensity = max_val * random.uniform(0.7, 1.0)
                y, x = np.ogrid[:rows, :cols]; blob_mask = ((x - cx)**2 + (y - cy)**2 <= blob_rad**2)
                pixels[blob_mask & mask] = np.maximum(pixels[blob_mask & mask], blob_intensity)
    # --- End Modality Specific Generation ---

    pixels = np.clip(pixels, min_val, max_val)
    pixel_array = pixels.astype(dtype)
    return pixel_array.tobytes()

def create_basic_dicom_dataset(modality, sop_class_uid):
    """Creates a base Dataset with common tags."""
    # (Function remains unchanged)
    ds = Dataset()
    _placeholder_uid = "1.2.3.0.0.0.0" # Placeholder UID

    # === Essential Metadata Setup ===
    ds.SpecificCharacterSet = DEFAULT_CHARACTER_SET # Set character set *early*
    ds.SOPClassUID = sop_class_uid
    ds.SOPInstanceUID = _placeholder_uid # Will be replaced per instance

    # === Patient Module ===
    ds.PatientName = "Unknown^Unknown"
    ds.PatientID = "Unknown"
    ds.PatientBirthDate = "19700101"
    ds.PatientSex = random.choice(["M", "F", "O"])

    # === General Study Module ===
    ds.StudyInstanceUID = _placeholder_uid # Will be replaced per study
    ds.StudyDate = "19000101"
    ds.StudyTime = datetime.datetime.now().strftime("%H%M%S.%f")[:13]
    ds.ReferringPhysicianName = "Test^Physician"
    ds.StudyID = generate_random_string(8)
    ds.AccessionNumber = "Unknown"
    ds.StudyDescription = "Default Study Description" # Will be replaced

    # === General Series Module ===
    ds.Modality = modality
    ds.SeriesInstanceUID = _placeholder_uid # Will be replaced per series
    ds.SeriesNumber = "1"
    # Series Date/Time usually set later based on first instance
    # BodyPartExamined will be added here if applicable, later in the script

    # === General Equipment Module ===
    ds.InstitutionName = "Default Institution" # Will be replaced
    ds.Manufacturer = "PyDICOM Virtual Scanner Co."

    # === Image Specific Defaults (if not SR) ===
    if modality != "SR":
        # --- General Image Module ---
        ds.InstanceNumber = "1" # Will be replaced per instance
        # Acquisition Date/Time/Content Date/Time set later

        # --- Image Plane Module ---
        ds.PatientOrientation = "A\\P" # Example, can be overridden
        # Pixel Spacing / Slice Thickness added conditionally later

        # --- Image Pixel Module ---
        ds.SamplesPerPixel = 1
        ds.PhotometricInterpretation = "MONOCHROME2"
        ds.Rows = 512
        ds.Columns = 512
        ds.BitsAllocated = 16
        ds.BitsStored = 12
        ds.HighBit = 11
        ds.PixelRepresentation = 0 # 0 = unsigned integer

        # --- VOI LUT Module (or Rescale) ---
        ds.RescaleIntercept = "0"
        ds.RescaleSlope = "1"
        # Window Center/Width added conditionally later

        # --- Pixel Data ---
        ds.PixelData = b'' # Placeholder

    # === SR Specific Placeholders ===
    if modality == "SR":
        # --- SR Document General Module ---
        ds.ValueType = "CONTAINER"
        ds.ContinuityOfContent = "SEPARATE"
        ds.CompletionFlag = "COMPLETE"
        ds.VerificationFlag = "UNVERIFIED"
        ds.ContentDate = ds.StudyDate # Will be updated
        ds.ContentTime = ds.StudyTime # Will be updated
        ds.InstanceNumber = "1" # Will be replaced per instance

        # --- SR Document Content Module (Basic Structure) ---
        content_sequence = Sequence()
        ds.ContentSequence = content_sequence

        # Container for the main report
        container_item = Dataset()
        container_item.RelationshipType = "CONTAINS"
        container_item.ValueType = "CONTAINER"
        # Concept Name: Diagnostic Report
        concept_name_code_seq = Sequence()
        container_item.ConceptNameCodeSequence = concept_name_code_seq
        concept_code_item = Dataset()
        concept_code_item.CodeValue = "113011"
        concept_code_item.CodingSchemeDesignator = "DCM"
        concept_code_item.CodeMeaning = "Diagnostic Report"
        concept_name_code_seq.append(concept_code_item)
        # Content Sequence within the container
        container_item.ContentSequence = Sequence()

        # Text item for findings/report text
        text_content_item = Dataset()
        text_content_item.RelationshipType = "CONTAINS"
        text_content_item.ValueType = "TEXT"
        # Concept Name: Findings
        text_concept_name_code_seq = Sequence()
        text_content_item.ConceptNameCodeSequence = text_concept_name_code_seq
        text_concept_code_item = Dataset()
        text_concept_code_item.CodeValue = "121071"
        text_concept_code_item.CodingSchemeDesignator = "DCM"
        text_concept_code_item.CodeMeaning = "Findings"
        text_concept_name_code_seq.append(text_concept_code_item)
        # Actual text value
        text_content_item.TextValue = "Placeholder Report Text" # Will be replaced
        # Add text item to container's sequence
        container_item.ContentSequence.append(text_content_item)
        # Add container to main content sequence
        content_sequence.append(container_item)

    return ds

def create_file_meta():
    """Creates the File Meta Information dataset."""
    # (Function remains unchanged)
    file_meta = FileMetaDataset()
    file_meta.FileMetaInformationVersion = b'\x00\x01'
    file_meta.MediaStorageSOPClassUID = '' # Will be set per instance
    file_meta.MediaStorageSOPInstanceUID = '' # Will be set per instance
    file_meta.TransferSyntaxUID = ExplicitVRLittleEndian
    file_meta.ImplementationClassUID = pydicom.uid.PYDICOM_IMPLEMENTATION_UID
    file_meta.ImplementationVersionName = "PYDICOM " + pydicom.__version__
    return file_meta

def apply_overrides(dataset, overrides_dict, quiet=False): # Added quiet flag
    """Applies specified overrides to the dataset using attribute access."""
    if not overrides_dict: return
    if not quiet: # Check quiet flag
        print("  Applying overrides:")
    for keyword, value in overrides_dict.items():
        try:
            tag = tag_for_keyword(keyword) # Use function to handle potential case issues/lookup
            if tag is None and keyword not in dataset:
                 # If keyword is not standard AND not already in dataset (e.g. private tag)
                 if not quiet:
                     print(f"    - Warning: Unknown DICOM keyword '{keyword}' not found in standard dictionary or dataset. Attempting direct assignment.")
                 setattr(dataset, keyword, value)
                 if not quiet:
                     print(f"    - Set {keyword} = {value} (non-standard/private)")
                 continue # Skip VR/encoding logic for unknown tags

            # If tag is known or keyword already exists in dataset
            if tag is not None:
                element = dataset.get(tag)
                vr = dictionary_VR(tag) if element is None else element.VR
            else: # Keyword must exist in dataset (e.g. private tag added earlier)
                element = dataset[keyword]
                vr = element.VR # Get VR from existing element

            # Perform the assignment (pydicom handles encoding for text VRs if SpecificCharacterSet is set)
            setattr(dataset, keyword, value)

            if not quiet: # Check quiet flag
                final_value = getattr(dataset, keyword, "!!! Error retrieving value !!!")
                # Limit printing long byte strings (like PixelData if overridden)
                if isinstance(final_value, bytes) and len(final_value) > 100:
                    final_value_repr = f"<bytes, len={len(final_value)}>"
                else:
                    final_value_repr = repr(final_value) # Use repr for clarity
                print(f"    - Set {keyword} = {final_value_repr} (VR: {vr})")

        except Exception as e:
            # Always print errors to stderr
            print(f"    - Error: Could not set {keyword} to {value}. Error: {e}", file=sys.stderr)

def get_body_part_options(study_desc, modality, quiet=False):
    """
    Gets a list of BodyPartExamined values based on StudyDescription and modality.
    Returns a list, with the first item being the "primary" choice.
    """
    body_parts = STUDY_DESCRIPTION_TO_BODY_PARTS.get(study_desc)
    if body_parts:
        return body_parts

    # Fallback to modality-specific default if StudyDescription not found
    modality_fallback_key = f"DEFAULT_{modality.upper()}"
    body_parts = STUDY_DESCRIPTION_TO_BODY_PARTS.get(modality_fallback_key)
    if body_parts:
        if not quiet:
            print(f"  Note: Using modality-specific fallback BodyPartExamined for '{study_desc}' (Modality: {modality}).")
        return body_parts

    # Absolute fallback
    if not quiet:
        print(f"  Warning: No specific BodyPartExamined mapping for '{study_desc}' or modality '{modality}'. Using general fallback.", file=sys.stderr)
    return STUDY_DESCRIPTION_TO_BODY_PARTS["DEFAULT_OVERALL"]


# --- Main Script ---

if __name__ == "__main__":
    # --- Argument Parsing ---
    parser = argparse.ArgumentParser(description="Generate a DICOM study with random values, outputting to a unique study directory.")
    parser.add_argument(
        '--set',
        nargs=2, action='append', metavar=('TAG_KEYWORD', 'VALUE'),
        dest='overrides',
        help='Override a specific DICOM tag (e.g., PatientID, PatientName, InstitutionName, StudyDescription, BodyPartExamined). Use pydicom keyword. Can be used multiple times.'
    )
    parser.add_argument(
        '--generate-pixels',
        action='store_true', dest='generate_pixels',
        help='Generate plausible fake pixel data. If omitted, pixel data will be zero bytes.'
    )
    parser.add_argument(
        '--base-dir',
        default=BASE_OUTPUT_DIR, # Use the configured default
        help=f'Base directory to create study subdirectories in (default: {BASE_OUTPUT_DIR})'
    )
    parser.add_argument(
        '--quiet', '-q',
        action='store_true',
        help='Suppress informational print statements during execution (errors will still be shown).'
    )
    # --- NEW: Added jumble-body-part flag ---
    parser.add_argument(
        '--jumble-body-part',
        action='store_true',
        dest='jumble_body_part',
        help='If set, BodyPartExamined will vary (plausibly) for each instance within the series. Otherwise, it is consistent.'
    )
    parser.add_argument(
        '--num-studies',
        type=int,
        default=1,
        help='Number of studies to generate (default: 1)'
    )
    args = parser.parse_args()
    overrides_dict = {item[0]: item[1] for item in args.overrides} if args.overrides else {}

    # --- Print Configuration Summary ---
    if not args.quiet:
        print("-" * 30)
        print("Starting DICOM study generation...")
        if overrides_dict:
            print("Overrides specified:")
            for k, v in overrides_dict.items(): print(f"  {k}: {v}")
        if args.generate_pixels:
            print("Plausible pixel data generation ENABLED.")
            if not HAS_SCIPY: print("Note: 'scipy' not installed. Pixel data smoothing will be skipped.")
        else:
            print("Plausible pixel data generation DISABLED (use --generate-pixels to enable).")
        if args.jumble_body_part:
            print("BodyPartExamined jumbling ENABLED.")
        else:
            print("BodyPartExamined jumbling DISABLED (will be consistent per series).")
        print(f"Base output directory: {Path(args.base_dir).resolve()}")
        print("-" * 30)

    fake = Faker() # Initialize Faker

    # --- Generate Multiple Studies ---
    for study_num in range(args.num_studies):
        if args.num_studies > 1 and not args.quiet:
            print(f"\n{'='*50}")
            print(f"GENERATING STUDY {study_num + 1} OF {args.num_studies}")
            print(f"{'='*50}")

        # --- Generate Study-Level Consistent Data ---
        # UIDs and Identifiers (generate new values for each study unless specifically overridden)
        if 'StudyInstanceUID' in overrides_dict:
            study_instance_uid = overrides_dict['StudyInstanceUID']
        else:
            study_instance_uid = generate_uid()
            
        if 'PatientName' in overrides_dict:
            patient_name = overrides_dict['PatientName']
        else:
            patient_name = generate_patient_name_pn(fake)
            
        if 'PatientID' in overrides_dict:
            patient_id = overrides_dict['PatientID']
        else:
            patient_id = generate_random_string(PATIENT_ID_LENGTH, string.digits)
            
        if 'AccessionNumber' in overrides_dict:
            accession_number = overrides_dict['AccessionNumber']
        else:
            accession_number = generate_random_string(ACCESSION_NUMBER_LENGTH)
            
        if 'InstitutionName' in overrides_dict:
            institution_name = overrides_dict['InstitutionName']
        else:
            institution_name = fake.company() + " " + random.choice(["Medical Center", "Hospital", "Clinic", "Imaging"])
            
        if 'StudyDate' in overrides_dict:
            study_date = overrides_dict['StudyDate']
        else:
            study_date = random_dicom_date_within_last_100_years()
            
        if 'StudyTime' in overrides_dict:
            study_time_base = overrides_dict['StudyTime']
        else:
            study_time_base = datetime.datetime.now().strftime("%H%M%S")

        # Patient birth date: random within last 100 years, not after StudyDate (unless overridden)
        if 'PatientBirthDate' in overrides_dict:
            patient_birth_date = overrides_dict['PatientBirthDate']
        else:
            patient_birth_date = random_dicom_birthdate_before(study_date)

        # --- Choose Imaging Modality for the Study ---
        if 'Modality' in overrides_dict:
            chosen_modality = overrides_dict['Modality']
        else:
            chosen_modality = random.choice(IMAGING_MODALITIES)
            
        if chosen_modality not in SOP_CLASS_UIDS or chosen_modality == "SR":
             print(f"Warning: Invalid/non-imaging modality '{chosen_modality}' selected or specified. Defaulting imaging component to CT.", file=sys.stderr) # Warning to stderr
             chosen_modality_for_images = "CT"
        else:
             chosen_modality_for_images = chosen_modality
        imaging_sop_class_uid = SOP_CLASS_UIDS[chosen_modality_for_images]

        # Generate Study Description based on modality
        possible_descriptions = MODALITY_DESCRIPTIONS.get(chosen_modality_for_images, MODALITY_DESCRIPTIONS['DEFAULT'])
        if 'StudyDescription' in overrides_dict:
            study_description = overrides_dict['StudyDescription']
        else:
            study_description = random.choice(possible_descriptions)

        # --- NEW: Determine BodyPartExamined for the series ---
        # Get the list of possible body parts for this study description and modality
        body_part_options_for_study = get_body_part_options(study_description, chosen_modality_for_images, quiet=args.quiet)
        # The primary body part is the first in the list (used if not jumbling)
        primary_body_part_examined = body_part_options_for_study[0]
        # If jumbling, we'll pick from body_part_options_for_study for each instance.

        if not args.quiet:
            print(f"Generating a {chosen_modality_for_images} study with 1 SR report.")
            print(f"Institution: {institution_name}")
            print(f"Study Description: {study_description}")
            print(f"Primary BodyPartExamined for series: {primary_body_part_examined}")
            if args.jumble_body_part:
                print(f"  (Jumbling active, will pick from: {body_part_options_for_study})")

        # --- Generate Series UIDs ---
        if 'SeriesInstanceUID' in overrides_dict:
            imaging_series_uid = overrides_dict['SeriesInstanceUID']
        else:
            imaging_series_uid = generate_uid()
            
        sr_series_uid_default = generate_uid()
        if 'SeriesInstanceUID_SR' in overrides_dict:
            sr_series_uid = overrides_dict['SeriesInstanceUID_SR']
        elif 'SeriesInstanceUID' in overrides_dict:
            sr_series_uid = overrides_dict['SeriesInstanceUID']
        else:
            sr_series_uid = sr_series_uid_default

        if not args.quiet:
            print("-" * 30)
            print(f"Study Instance UID: {study_instance_uid}")
            print(f"Patient ID:         {patient_id}")
            print(f"Patient Name:       {patient_name}")
            print(f"Accession Number:   {accession_number}")
            print(f"Imaging Series UID: {imaging_series_uid}")
            print(f"SR Series UID:      {sr_series_uid}")
            print("-" * 30)

        study_output_path = Path(args.base_dir) / study_instance_uid
        try:
            study_output_path.mkdir(parents=True, exist_ok=True)
            if not args.quiet:
                print(f"Output directory for this study: {study_output_path.resolve()}")
        except OSError as e:
            print(f"Error creating output directory {study_output_path}: {e}", file=sys.stderr)
            print("Please check permissions and path validity.", file=sys.stderr)
            sys.exit(1)
        if not args.quiet:
            print("-" * 30)

        # --- Multiframe logic for US and XA ---
        multiframes_modalities = ["US", "XA"]
        if chosen_modality_for_images in multiframes_modalities:
            if not args.quiet:
                print(f"Generating 1 multiframe {chosen_modality_for_images} object with {NUM_IMAGES} frames...")
            ds = create_basic_dicom_dataset(chosen_modality_for_images, imaging_sop_class_uid)
            ds.PatientName = patient_name
            ds.PatientID = patient_id
            ds.PatientBirthDate = patient_birth_date
            ds.StudyInstanceUID = study_instance_uid
            ds.StudyDate = study_date
            ds.StudyTime = study_time_base
            ds.InstitutionName = institution_name
            ds.StudyDescription = study_description
            ds.SeriesInstanceUID = imaging_series_uid
            ds.SeriesNumber = overrides_dict.get('SeriesNumber', "1")
            ds.InstanceNumber = "1"
            ds.SOPInstanceUID = generate_uid()
            # BodyPartExamined
            if args.jumble_body_part:
                ds.BodyPartExamined = random.choice(body_part_options_for_study)
            else:
                ds.BodyPartExamined = primary_body_part_examined
            # Timing
            first_instance_time_str = None
            frame_times = []
            for i in range(NUM_IMAGES):
                instance_time = (datetime.datetime.strptime(study_time_base.split('.')[0], "%H%M%S") +
                                 datetime.timedelta(seconds=i*0.5 + random.uniform(0, 0.2)))
                current_time_str = instance_time.strftime("%H%M%S.%f")[:13]
                frame_times.append(current_time_str)
                if i == 0:
                    first_instance_time_str = current_time_str
            ds.SeriesDate = study_date
            ds.SeriesTime = first_instance_time_str
            ds.AcquisitionDateTime = study_date + first_instance_time_str
            ds.AcquisitionTime = first_instance_time_str
            ds.ContentDate = study_date
            ds.ContentTime = first_instance_time_str
            # Windowing
            try:
                center = (1 << (ds.BitsStored - 1))
                width = (1 << ds.BitsStored)
                ds.WindowCenter = f"{center:.0f}"
                ds.WindowWidth = f"{width:.0f}"
            except AttributeError:
                pass
            # Generate all frames' pixel data
            frame_bytes = []
            for i in range(NUM_IMAGES):
                if args.generate_pixels:
                    try:
                        frame_bytes.append(generate_plausible_pixel_data(ds, i+1, quiet=args.quiet))
                    except Exception as pix_err:
                        print(f"    ***ERROR*** generating pixel data for Frame {i+1}: {pix_err}", file=sys.stderr)
                        try:
                            expected_bytes = ds.Rows * ds.Columns * (ds.BitsAllocated // 8) * ds.SamplesPerPixel
                            frame_bytes.append(b'\x00' * expected_bytes)
                            if not args.quiet:
                                print(f"    Falling back to zero bytes for Frame {i+1}.")
                        except AttributeError:
                            print(f"    ***WARNING*** Cannot calculate fallback zero bytes - missing attributes. Frame will be empty.", file=sys.stderr)
                            frame_bytes.append(b'')
                else:
                    if not args.quiet:
                        print(f"    Skipping plausible pixel generation for Frame {i+1}. Setting zero bytes.")
                    try:
                        expected_bytes = ds.Rows * ds.Columns * (ds.BitsAllocated // 8) * ds.SamplesPerPixel
                        frame_bytes.append(b'\x00' * expected_bytes)
                    except AttributeError:
                        print(f"    ***WARNING*** Frame {i+1}: Could not calculate expected bytes for zero pixel data. Frame will be empty.", file=sys.stderr)
                        frame_bytes.append(b'')
            ds.NumberOfFrames = str(NUM_IMAGES)
            ds.PixelData = b''.join(frame_bytes)
            apply_overrides(ds, overrides_dict, quiet=args.quiet)
            ds.SOPInstanceUID = ds.SOPInstanceUID
            ds.SOPClassUID = imaging_sop_class_uid
            ds.Modality = chosen_modality_for_images
            if not hasattr(ds, 'SpecificCharacterSet') or not ds.SpecificCharacterSet:
                if not args.quiet:
                    print(f"    Applying default SpecificCharacterSet ({DEFAULT_CHARACTER_SET}) after overrides.")
                ds.SpecificCharacterSet = DEFAULT_CHARACTER_SET
            # PixelData length check
            try:
                if all(hasattr(ds, attr) for attr in ['Rows', 'Columns', 'BitsAllocated', 'SamplesPerPixel']):
                    expected_bytes = ds.Rows * ds.Columns * (ds.BitsAllocated // 8) * ds.SamplesPerPixel * NUM_IMAGES
                    if hasattr(ds, 'PixelData') and ds.PixelData is not None:
                        if len(ds.PixelData) != expected_bytes:
                            print(f"    ***WARNING*** Multiframe: PixelData length mismatch after overrides!", file=sys.stderr)
                            print(f"    Expected {expected_bytes}, got {len(ds.PixelData)}. Reverting to zero bytes.", file=sys.stderr)
                            ds.PixelData = b'\x00' * expected_bytes
                    else:
                        if not args.quiet:
                            print(f"    PixelData missing or None after overrides for multiframe. Setting zero bytes.")
                        ds.PixelData = b'\x00' * expected_bytes
                elif hasattr(ds, 'PixelData') and ds.PixelData:
                    print(f"    ***WARNING*** Multiframe: Cannot verify PixelData length due to missing dimension attributes after overrides.", file=sys.stderr)
            except (AttributeError, TypeError) as len_check_err:
                print(f"    ***WARNING*** Multiframe: Error during PixelData length check: {len_check_err}. PixelData might be inconsistent.", file=sys.stderr)
            file_meta = create_file_meta()
            file_meta.MediaStorageSOPClassUID = imaging_sop_class_uid
            file_meta.MediaStorageSOPInstanceUID = ds.SOPInstanceUID
            file_ds = pydicom.FileDataset(
                filename_or_obj=None, dataset=ds, file_meta=file_meta, preamble=b"\0" * 128
            )
            filename = study_output_path / f"{ds.Modality}_{ds.SOPInstanceUID}.dcm"
            if not args.quiet:
                bpe_info = f" (BPE: {ds.BodyPartExamined})" if hasattr(ds, "BodyPartExamined") and ds.BodyPartExamined else ""
                print(f"    Saving: {filename.name}{bpe_info}")
            try:
                file_ds.save_as(filename, write_like_original=False)
            except Exception as e:
                print(f"    ***ERROR*** Failed to save file {filename.name}: {e}", file=sys.stderr)
            if not args.quiet:
                print(f"Finished generating 1 multiframe {chosen_modality_for_images} object.")
                print("-" * 30)

        else:
            # --- Standard (non-multiframe) logic for other modalities ---
            if not args.quiet:
                print(f"Generating {NUM_IMAGES} {chosen_modality_for_images} objects...")
            first_instance_time_str = None
            for i in range(NUM_IMAGES):
                instance_num = i + 1
                if not args.quiet:
                    print(f"  Creating Instance {instance_num}/{NUM_IMAGES}...")
                ds = create_basic_dicom_dataset(chosen_modality_for_images, imaging_sop_class_uid)
                ds.PatientName = patient_name
                ds.PatientID = patient_id
                ds.PatientBirthDate = patient_birth_date
                ds.AccessionNumber = accession_number
                ds.StudyInstanceUID = study_instance_uid
                ds.StudyDate = study_date
                ds.StudyTime = study_time_base
                ds.InstitutionName = institution_name
                ds.StudyDescription = study_description
                ds.SeriesInstanceUID = imaging_series_uid
                ds.SeriesNumber = overrides_dict.get('SeriesNumber', "1")
                ds.InstanceNumber = str(instance_num)
                ds.SOPInstanceUID = generate_uid()
                # --- NEW: Set BodyPartExamined ---
                if chosen_modality_for_images != "SR":
                    if args.jumble_body_part:
                        ds.BodyPartExamined = random.choice(body_part_options_for_study)
                        if not args.quiet:
                            print(f"    Instance {instance_num} BodyPartExamined (jumbled): {ds.BodyPartExamined}")
                    else:
                        ds.BodyPartExamined = primary_body_part_examined
                instance_time = (datetime.datetime.strptime(study_time_base.split('.')[0], "%H%M%S") +
                                 datetime.timedelta(seconds=i*0.5 + random.uniform(0, 0.2)))
                current_time_str = instance_time.strftime("%H%M%S.%f")[:13]
                ds.AcquisitionDateTime = study_date + current_time_str
                ds.AcquisitionTime = current_time_str
                ds.ContentDate = study_date
                ds.ContentTime = current_time_str
                if i == 0:
                    first_instance_time_str = current_time_str
                    ds.SeriesDate = study_date
                    ds.SeriesTime = first_instance_time_str
                else:
                    ds.SeriesDate = study_date
                    ds.SeriesTime = first_instance_time_str
            if chosen_modality_for_images in ["CT", "MR"]:
                slice_pos = instance_num * 5.0 + random.uniform(-1.0, 1.0)
                ds.SliceLocation = f"{slice_pos:.2f}"
                ds.SliceThickness = "5.0"
                ds.PixelSpacing = ["0.8", "0.8"]
                ds.WindowCenter = "40"
                ds.WindowWidth = "400"
            elif chosen_modality_for_images in ["CR", "XA", "US"]:
                try:
                    center = (1 << (ds.BitsStored - 1))
                    width = (1 << ds.BitsStored)
                    ds.WindowCenter = f"{center:.0f}"
                    ds.WindowWidth = f"{width:.0f}"
                except AttributeError:
                    pass
            if args.generate_pixels:
                try:
                    ds.PixelData = generate_plausible_pixel_data(ds, instance_num, quiet=args.quiet)
                except Exception as pix_err:
                    print(f"    ***ERROR*** generating pixel data for Instance {instance_num}: {pix_err}", file=sys.stderr)
                    try:
                        expected_bytes = ds.Rows * ds.Columns * (ds.BitsAllocated // 8) * ds.SamplesPerPixel
                        ds.PixelData = b'\x00' * expected_bytes
                        if not args.quiet:
                            print(f"    Falling back to zero bytes for PixelData.")
                    except AttributeError:
                        print(f"    ***WARNING*** Cannot calculate fallback zero bytes - missing attributes. PixelData will be empty.", file=sys.stderr)
                        ds.PixelData = b''
            else:
                if not args.quiet:
                    print(f"    Skipping plausible pixel generation for Instance {instance_num}. Setting zero bytes.")
                try:
                    expected_bytes = ds.Rows * ds.Columns * (ds.BitsAllocated // 8) * ds.SamplesPerPixel
                    ds.PixelData = b'\x00' * expected_bytes
                except AttributeError:
                    print(f"    ***WARNING*** Instance {instance_num}: Could not calculate expected bytes for zero pixel data. PixelData may be missing.", file=sys.stderr)
                    ds.PixelData = b''
            apply_overrides(ds, overrides_dict, quiet=args.quiet)
            ds.SOPInstanceUID = ds.SOPInstanceUID
            ds.SOPClassUID = imaging_sop_class_uid
            ds.Modality = chosen_modality_for_images
            if not hasattr(ds, 'SpecificCharacterSet') or not ds.SpecificCharacterSet:
                if not args.quiet:
                    print(f"    Applying default SpecificCharacterSet ({DEFAULT_CHARACTER_SET}) after overrides.")
                ds.SpecificCharacterSet = DEFAULT_CHARACTER_SET
            try:
                if all(hasattr(ds, attr) for attr in ['Rows', 'Columns', 'BitsAllocated', 'SamplesPerPixel']):
                    if not all(isinstance(getattr(ds, attr), (int, float)) for attr in ['Rows', 'Columns', 'BitsAllocated', 'SamplesPerPixel']):
                        raise TypeError("Pixel dimension attributes are not numeric")
                    expected_bytes = ds.Rows * ds.Columns * (ds.BitsAllocated // 8) * ds.SamplesPerPixel
                    if hasattr(ds, 'PixelData') and ds.PixelData is not None:
                        if len(ds.PixelData) != expected_bytes:
                            print(f"    ***WARNING*** Instance {instance_num}: PixelData length mismatch after overrides!", file=sys.stderr)
                            print(f"    Expected {expected_bytes}, got {len(ds.PixelData)}. Reverting to zero bytes.", file=sys.stderr)
                            ds.PixelData = b'\x00' * expected_bytes
                    else:
                        if not args.quiet:
                            print(f"    PixelData missing or None after overrides for Instance {instance_num}. Setting zero bytes.")
                        ds.PixelData = b'\x00' * expected_bytes
                elif hasattr(ds, 'PixelData') and ds.PixelData:
                    print(f"    ***WARNING*** Instance {instance_num}: Cannot verify PixelData length due to missing dimension attributes after overrides.", file=sys.stderr)
            except (AttributeError, TypeError) as len_check_err:
                print(f"    ***WARNING*** Instance {instance_num}: Error during PixelData length check: {len_check_err}. PixelData might be inconsistent.", file=sys.stderr)
            file_meta = create_file_meta()
            file_meta.MediaStorageSOPClassUID = imaging_sop_class_uid
            file_meta.MediaStorageSOPInstanceUID = ds.SOPInstanceUID
            file_ds = pydicom.FileDataset(
                filename_or_obj=None, dataset=ds, file_meta=file_meta, preamble=b"\0" * 128
            )
            filename = study_output_path / f"{ds.Modality}_{ds.SOPInstanceUID}.dcm"
            if not args.quiet:
                bpe_info = f" (BPE: {ds.BodyPartExamined})" if hasattr(ds, "BodyPartExamined") and ds.BodyPartExamined else ""
                print(f"    Saving: {filename.name}{bpe_info}")
            try:
                file_ds.save_as(filename, write_like_original=False)
            except Exception as e:
                print(f"    ***ERROR*** Failed to save file {filename.name}: {e}", file=sys.stderr)
        if not args.quiet:
            print(f"Finished generating {NUM_IMAGES} image objects.")
            print("-" * 30)

        # --- Generate the Structured Report (SR) Object ---
        # (SR generation remains largely unchanged, as BodyPartExamined is not typically part of the SR root dataset here)
        if not args.quiet:
            print("Generating SR object...")
        sr_sop_class_uid = SOP_CLASS_UIDS["SR"]
        ds_sr = create_basic_dicom_dataset("SR", sr_sop_class_uid)

        ds_sr.PatientName = patient_name
        ds_sr.PatientID = patient_id
        ds_sr.PatientBirthDate = patient_birth_date
        ds_sr.AccessionNumber = accession_number
        ds_sr.StudyInstanceUID = study_instance_uid
        ds_sr.StudyDate = study_date
        ds_sr.StudyTime = study_time_base
        ds_sr.InstitutionName = institution_name
        ds_sr.StudyDescription = study_description

        ds_sr.SeriesInstanceUID = sr_series_uid
        ds_sr.SeriesNumber = overrides_dict.get('SeriesNumber_SR', overrides_dict.get('SeriesNumber', "99"))
        ds_sr.InstanceNumber = "1"
        ds_sr.SOPInstanceUID = generate_uid()

        sr_content_time_offset = datetime.timedelta(minutes=random.randint(5, 30), seconds=random.uniform(0, 59))
        sr_base_time_str = first_instance_time_str if first_instance_time_str else study_time_base
        try:
            sr_base_dt = datetime.datetime.strptime(sr_base_time_str.split('.')[0], "%H%M%S")
            sr_content_dt = sr_base_dt + sr_content_time_offset
            sr_time_str = sr_content_dt.strftime("%H%M%S.%f")[:13]
        except ValueError:
            print(f"    Warning: Could not parse base time '{sr_base_time_str}' for SR timing offset. Using study base.", file=sys.stderr)
            sr_base_dt = datetime.datetime.strptime(study_time_base.split('.')[0], "%H%M%S")
            sr_content_dt = sr_base_dt + sr_content_time_offset
            sr_time_str = sr_content_dt.strftime("%H%M%S.%f")[:13]

        ds_sr.ContentDate = study_date
        ds_sr.ContentTime = sr_time_str
        ds_sr.SeriesDate = study_date
        ds_sr.SeriesTime = sr_time_str

        report_text = generate_fake_report_text(fake, chosen_modality_for_images, study_description)
        try:
            if (hasattr(ds_sr, 'ContentSequence') and ds_sr.ContentSequence and
                hasattr(ds_sr.ContentSequence[0], 'ContentSequence') and ds_sr.ContentSequence[0].ContentSequence and
                hasattr(ds_sr.ContentSequence[0].ContentSequence[0], 'TextValue')):
                 ds_sr.ContentSequence[0].ContentSequence[0].TextValue = report_text
                 if not args.quiet:
                     print("    Set SR report text.")
            else:
                 print("    ***WARNING*** SR ContentSequence structure invalid or missing. Cannot set report text.", file=sys.stderr)
                 try:
                     if hasattr(ds_sr, 'ContentSequence') and ds_sr.ContentSequence:
                         fallback_text_item = Dataset()
                         fallback_text_item.RelationshipType = "CONTAINS"; fallback_text_item.ValueType = "TEXT"
                         fallback_text_item.ConceptNameCodeSequence = Sequence([Dataset(CodeValue="121071", CodingSchemeDesignator="DCM", CodeMeaning="Findings")])
                         fallback_text_item.TextValue = "Fallback Report Text - Structure Error"
                         if ds_sr.ContentSequence and hasattr(ds_sr.ContentSequence[0], 'ContentSequence'):
                            ds_sr.ContentSequence[0].ContentSequence.append(fallback_text_item)
                         elif ds_sr.ContentSequence:
                            ds_sr.ContentSequence.append(fallback_text_item)
                         else:
                             ds_sr.ContentSequence = Sequence([fallback_text_item])
                         print("    Added fallback text item to SR.", file=sys.stderr)
                     else:
                         print("    Cannot add fallback text, ContentSequence missing entirely.", file=sys.stderr)
                 except Exception as fallback_err:
                     print(f"    ***ERROR*** Could not even add fallback SR text: {fallback_err}", file=sys.stderr)
        except Exception as e:
            print(f"    ***ERROR*** Unexpected error setting SR TextValue: {e}", file=sys.stderr)


        apply_overrides(ds_sr, overrides_dict, quiet=args.quiet)

        ds_sr.SOPInstanceUID = ds_sr.SOPInstanceUID
        ds_sr.SOPClassUID = sr_sop_class_uid
        ds_sr.Modality = "SR"
        if not hasattr(ds_sr, 'SpecificCharacterSet') or not ds_sr.SpecificCharacterSet:
            if not args.quiet:
                print(f"    Applying default SpecificCharacterSet ({DEFAULT_CHARACTER_SET}) to SR after overrides.")
            ds_sr.SpecificCharacterSet = DEFAULT_CHARACTER_SET

        file_meta_sr = create_file_meta()
        file_meta_sr.MediaStorageSOPClassUID = sr_sop_class_uid
        file_meta_sr.MediaStorageSOPInstanceUID = ds_sr.SOPInstanceUID

        file_ds_sr = pydicom.FileDataset(
            filename_or_obj=None, dataset=ds_sr, file_meta=file_meta_sr, preamble=b"\0" * 128
        )

        filename_sr = study_output_path / f"SR_{ds_sr.SOPInstanceUID}.dcm"
        if not args.quiet:
            print(f"    Saving: {filename_sr.name}")
        try:
            file_ds_sr.save_as(filename_sr, write_like_original=False)
            if not args.quiet:
                print("Finished generating SR object.")
        except Exception as e:
            print(f"    ***ERROR*** Failed to save SR file {filename_sr.name}: {e}", file=sys.stderr)


        if not args.quiet:
            print("-" * 30)
            print(f"Successfully generated {NUM_IMAGES + 1} DICOM objects for study {study_instance_uid}")
            print(f"Files saved in study directory: {study_output_path.resolve()}")
            print(f"(Base directory: {Path(args.base_dir).resolve()})")
            print("-" * 30)
